{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "tnttzAlrde3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ty-hVIYueo7m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "r9ZqlgT40fmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('updated_hate_speech2.csv',engine='python')\n",
        "X = data['Content'].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# We did a 80/20 split for training and testing. We later split the training set into training and validation\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OepVvs93d5-Y"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Naive Bayes**"
      ],
      "metadata": {
        "id": "QLwFbijVhZ_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose a Multinomial Naive Bayes because it works best with discrete features such as word counts or frequencies"
      ],
      "metadata": {
        "id": "H1wZjoGHfuy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "xz3DoG3ZPYe8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a TF-IDF vectorizer to preprocess the data to create vectors of the word frequencies\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "nb_X_train = vectorizer.fit_transform(train_X)\n",
        "nb_X_test = vectorizer.transform(test_X)"
      ],
      "metadata": {
        "id": "_I85bP6BPMLU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive = MultinomialNB()\n",
        "naive.fit(nb_X_train, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "L0sL8DpRP7NF",
        "outputId": "07b69938-6490-4f60-a823-9971083b50da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = naive.predict(nb_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "misclassified_samples = 0\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] != test_y[i]:\n",
        "        original_sentence = vectorizer.inverse_transform(nb_X_test[i])[0]\n",
        "        print(\"Sentence: \", \" \".join(original_sentence))\n",
        "        print(\"Actual Label: \", test_y[i])\n",
        "        print(\"Predicted Label: \", y_pred[i])\n",
        "        print(\" \")\n",
        "        misclassified_samples += 1\n",
        "    if misclassified_samples >= 5:\n",
        "        break\n",
        "\n",
        "print('Accuracy: %.3f' % accuracy_score(test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(test_y, y_pred))"
      ],
      "metadata": {
        "id": "0Idx_Zl1ethI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "34475dfb-37a8-47cf-98da-331ac9a3b18f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  really point people longer hate fuck bitch\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Sentence:  trump rick love listening interview fuck\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  plumber make kill family\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Sentence:  whatsoever welsh visit totally source seoul sentiments saying reliable regard reference prove professional position pathetic orders nonsense making look let know judge genes gather fueled father exactly dictate comments come break blessed anti accurate absolute\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  wow word wikipedia violation views view users user undeniable truth tracks template surprised suggest stop star slimy racist pushing puppet proven pretending policy news monkey meat manchus manchu managed making loser like just highly given fringe foul forward following false face ethnicity ethnically especially escape editing edit earn did created congratulations chinese calling blocking blocked blatant barnstar barn barbaric banana acting accusations\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Accuracy: 0.800\n",
            "Precision: 0.771\n",
            "Recall: 0.780\n",
            "F1: 0.776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**"
      ],
      "metadata": {
        "id": "lOagRMHpgItY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten\n",
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "-XLa7ATwgM5g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "VTw_oRzoSGrS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        word_embeddings[word] = embedding"
      ],
      "metadata": {
        "id": "HglATWOgRNg7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "#This tokenizes the text and counts the frequency of each token\n",
        "tokenizer.fit_on_texts(train_X)\n",
        "#create a vocabulary of the most frequently occurring words in the training data\n",
        "cnn_X_train = tokenizer.texts_to_sequences(train_X)\n",
        "cnn_X_val = tokenizer.texts_to_sequences(val_X)\n",
        "cnn_X_test = tokenizer.texts_to_sequences(test_X)"
      ],
      "metadata": {
        "id": "gn77FHx8RWl-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to pad the sequences here so they have the right shape\n",
        "maxlen = 100\n",
        "cnn_X_train = pad_sequences(cnn_X_train, padding='post', maxlen=maxlen)\n",
        "cnn_X_val = pad_sequences(cnn_X_val, padding='post', maxlen=maxlen)\n",
        "cnn_X_test = pad_sequences(cnn_X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "muG0FBB5Setb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the matrix for the embedding layer\n",
        "word_index = tokenizer.word_index\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # If word is not in pre-trained embeddings, use random vector\n",
        "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "id": "PGhYacqVSypl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Embedding(input_dim=len(word_index) + 1, output_dim=100, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
        "cnn.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(MaxPooling1D(pool_size=2))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(units=250, activation='relu'))\n",
        "cnn.add(Dropout(rate=0.2))\n",
        "cnn.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Hrj2u5XlTw8O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn.fit(cnn_X_train, train_y, epochs=10, batch_size=64, validation_data=(cnn_X_val, val_y), callbacks=[EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FYeth8UIUNJX",
        "outputId": "51e81ded-de5e-4341-c3f5-9750b2842f0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1681/1681 [==============================] - 53s 30ms/step - loss: 0.4766 - accuracy: 0.7673 - val_loss: 0.4433 - val_accuracy: 0.7886\n",
            "Epoch 2/10\n",
            "1681/1681 [==============================] - 48s 28ms/step - loss: 0.4155 - accuracy: 0.8062 - val_loss: 0.4180 - val_accuracy: 0.8052\n",
            "Epoch 3/10\n",
            "1681/1681 [==============================] - 47s 28ms/step - loss: 0.3848 - accuracy: 0.8248 - val_loss: 0.4210 - val_accuracy: 0.8060\n",
            "Epoch 4/10\n",
            "1681/1681 [==============================] - 54s 32ms/step - loss: 0.3548 - accuracy: 0.8402 - val_loss: 0.4250 - val_accuracy: 0.8078\n",
            "Epoch 5/10\n",
            "1681/1681 [==============================] - 48s 29ms/step - loss: 0.3218 - accuracy: 0.8578 - val_loss: 0.4462 - val_accuracy: 0.8056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f071d062fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn.predict(cnn_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "misclassified_samples = 0\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] != test_y[i]:\n",
        "        original_sentence = tokenizer.sequences_to_texts([cnn_X_test[i]])[0]\n",
        "        actual_label = test_y[i]\n",
        "        predicted_label = y_pred[i][0]\n",
        "        print(\"Sentence: \", original_sentence)\n",
        "        print(\"Actual Label: \", actual_label)\n",
        "        print(\"Predicted Label: \", predicted_label)\n",
        "        print(\" \")\n",
        "        misclassified_samples += 1\n",
        "    if misclassified_samples >= 5:\n",
        "        break\n",
        "        \n",
        "print('Accuracy: %.3f' % accuracy_score(test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(test_y, y_pred))"
      ],
      "metadata": {
        "id": "0HRn70Iyg6jU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5b4173d6-f295-4b0e-ddef-7b6c6598ffe6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1121/1121 [==============================] - 12s 11ms/step\n",
            "Sentence:  i really hate being a bitch to people but at this point i no longer give a fuck\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Sentence:  what are you doing afghan faggot i am bored louis watching netflix\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  how to play these niggas and bitches that be snakes\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  and you are in what position to give out orders dictate and judge exactly none none whatsoever you are only making yourself look absolute pathetic by saying such nonsense and in regard to your reference of the source being totally a reliable and accurate source give me a break very professional of yourself fueled with anti welsh sentiments too i gather let me know when you come to seoul to visit your professional father your comments prove that the professional genes have not blessed yourself\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  bolest reba recite\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Accuracy: 0.805\n",
            "Precision: 0.795\n",
            "Recall: 0.754\n",
            "F1: 0.774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RNN**"
      ],
      "metadata": {
        "id": "DsqnzfukgvVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "UhG9dkRElYbd"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "ZVEWzq8qSI_D"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        word_embeddings[word] = embedding"
      ],
      "metadata": {
        "id": "95SRRI0pYzrl"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Could include num_words = 500\n",
        "tokenizer = Tokenizer()\n",
        "#This tokenizes the text and counts the frequency of each token\n",
        "tokenizer.fit_on_texts(train_X)\n",
        "#create a vocabulary of the most frequently occurring words in the training data\n",
        "rnn_X_train = tokenizer.texts_to_sequences(train_X)\n",
        "rnn_X_val = tokenizer.texts_to_sequences(val_X)\n",
        "rnn_X_test = tokenizer.texts_to_sequences(test_X)"
      ],
      "metadata": {
        "id": "muYJiHvcY0RC"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to pad the sequences here so they have the right shape\n",
        "maxlen = 100\n",
        "rnn_X_train = pad_sequences(rnn_X_train, padding='post', maxlen=maxlen)\n",
        "rnn_X_val = pad_sequences(rnn_X_val, padding='post', maxlen=maxlen)\n",
        "rnn_X_test = pad_sequences(rnn_X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "Te68LBW5Y7KI"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the matrix for the embedding layer\n",
        "word_index = tokenizer.word_index\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # If word is not in pre-trained embeddings, use random vector\n",
        "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "id": "yieXKjpuYuO2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = Sequential()\n",
        "rnn.add(Embedding(len(word_index) + 1, embedding_dim, input_length=maxlen, \n",
        "                    weights=[embedding_matrix], trainable=False))\n",
        "rnn.add(LSTM(64))\n",
        "rnn.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "lc7OlHHTlY08"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "rnn.fit(rnn_X_train, train_y, epochs=10, batch_size=64, validation_data=(rnn_X_val, val_y), callbacks=[EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "njDHlXQwZTF9",
        "outputId": "818ecb63-e069-43cf-c905-9c7e0c296776"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1681/1681 [==============================] - 221s 130ms/step - loss: 0.6140 - accuracy: 0.6410 - val_loss: 0.5078 - val_accuracy: 0.7438\n",
            "Epoch 2/10\n",
            "1681/1681 [==============================] - 217s 129ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.4659 - val_accuracy: 0.7799\n",
            "Epoch 3/10\n",
            "1681/1681 [==============================] - 197s 117ms/step - loss: 0.4271 - accuracy: 0.8010 - val_loss: 0.4165 - val_accuracy: 0.8073\n",
            "Epoch 4/10\n",
            "1681/1681 [==============================] - 217s 129ms/step - loss: 0.4031 - accuracy: 0.8145 - val_loss: 0.4004 - val_accuracy: 0.8138\n",
            "Epoch 5/10\n",
            "1681/1681 [==============================] - 217s 129ms/step - loss: 0.3849 - accuracy: 0.8247 - val_loss: 0.4354 - val_accuracy: 0.7983\n",
            "Epoch 6/10\n",
            "1681/1681 [==============================] - 215s 128ms/step - loss: 0.3700 - accuracy: 0.8330 - val_loss: 0.3843 - val_accuracy: 0.8233\n",
            "Epoch 7/10\n",
            "1681/1681 [==============================] - 214s 127ms/step - loss: 0.3577 - accuracy: 0.8399 - val_loss: 0.3841 - val_accuracy: 0.8243\n",
            "Epoch 8/10\n",
            "1681/1681 [==============================] - 216s 129ms/step - loss: 0.3443 - accuracy: 0.8467 - val_loss: 0.3903 - val_accuracy: 0.8267\n",
            "Epoch 9/10\n",
            "1681/1681 [==============================] - 217s 129ms/step - loss: 0.3353 - accuracy: 0.8518 - val_loss: 0.3876 - val_accuracy: 0.8248\n",
            "Epoch 10/10\n",
            "1681/1681 [==============================] - 217s 129ms/step - loss: 0.3243 - accuracy: 0.8573 - val_loss: 0.3980 - val_accuracy: 0.8251\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0720405310>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rnn.predict(rnn_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "misclassified_samples = 0\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] != test_y[i]:\n",
        "        original_sentence = tokenizer.sequences_to_texts([rnn_X_test[i]])[0]\n",
        "        actual_label = test_y[i]\n",
        "        predicted_label = y_pred[i][0]\n",
        "        print(\"Sentence: \", original_sentence)\n",
        "        print(\"Actual Label: \", actual_label)\n",
        "        print(\"Predicted Label: \", predicted_label)\n",
        "        print(\" \")\n",
        "        misclassified_samples += 1\n",
        "    if misclassified_samples >= 5:\n",
        "        break\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(test_y, y_pred))"
      ],
      "metadata": {
        "id": "svqkoWDVfV7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5ac078f1-5888-4e0a-a81d-0aae2addfa86"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1121/1121 [==============================] - 25s 22ms/step\n",
            "Sentence:  how do you make a plumber cry you kill his family\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Sentence:  how to play these niggas and bitches that be snakes\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  and you are in what position to give out orders dictate and judge exactly none none whatsoever you are only making yourself look absolute pathetic by saying such nonsense and in regard to your reference of the source being totally a reliable and accurate source give me a break very professional of yourself fueled with anti welsh sentiments too i gather let me know when you come to seoul to visit your professional father your comments prove that the professional genes have not blessed yourself\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  views on wikipedia especially your foul slimy racist view that manchus are ethnically chinese you have proven yourself to be more barbaric than this monkey here is a banana congratulations on acting like a monkey wow so you have managed to earn the monkey s barn star you must be highly barbaric then stop making false accusations congratulations on calling user the h word well i have news for you user is not ethnically chinese so just face the truth and stop name calling you racist manchu otherwise i will get my meat puppet to stop you in your tracks\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  she got arrested for domestic violence against him ugh bitch\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Accuracy: 0.829\n",
            "Precision: 0.806\n",
            "Recall: 0.809\n",
            "F1: 0.808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combined CNN-LSTM**"
      ],
      "metadata": {
        "id": "r4iLqAtehiuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wanted to combine the CNN and RNN as we believe it will capture both short-distance and long-distance dependencies"
      ],
      "metadata": {
        "id": "YKtOUpYjhxwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, MaxPooling1D, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "fNj4wDC3hYwE"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "Bljh41HESKXI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        word_embeddings[word] = embedding"
      ],
      "metadata": {
        "id": "I57EFaWWjas_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Could include num_words = 500\n",
        "tokenizer = Tokenizer()\n",
        "#This tokenizes the text and counts the frequency of each token\n",
        "tokenizer.fit_on_texts(train_X)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "#create a vocabulary of the most frequently occurring words in the training data\n",
        "combined_X_train = tokenizer.texts_to_sequences(train_X)\n",
        "combined_X_val = tokenizer.texts_to_sequences(val_X)\n",
        "combined_X_test = tokenizer.texts_to_sequences(test_X)"
      ],
      "metadata": {
        "id": "eyU3dtMHjdcy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to pad the sequences here so they have the right shape\n",
        "maxlen = 100\n",
        "combined_X_train = pad_sequences(combined_X_train, padding='post', maxlen=maxlen)\n",
        "combined_X_val = pad_sequences(combined_X_val, padding='post', maxlen=maxlen)\n",
        "combined_X_test = pad_sequences(combined_X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "wml9jjesjmaw"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the matrix for the embedding layer\n",
        "word_index = tokenizer.word_index\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # If word is not in pre-trained embeddings, use random vector\n",
        "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "id": "h8CLHW_jju5H"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False)(inputs)\n",
        "conv_layer = Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu')(embedding_layer)\n",
        "pooling_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "\n",
        "lstm_layer = Bidirectional(LSTM(64))(pooling_layer)\n",
        "fc_layer = Dropout(0.5)(lstm_layer)\n",
        "\n",
        "outputs = Dense(1, activation='sigmoid')(fc_layer)\n",
        "CNNLSTM = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "AOfD5xXuiAAQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNNLSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# I used early stopping here to prevent overfitting since this model is prone to overfitting\n",
        "CNNLSTM.fit(combined_X_train, train_y, epochs=10, batch_size=128, validation_data=(combined_X_val, val_y), callbacks=[EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pc3CBMBZmQia",
        "outputId": "7a675c77-021e-4f57-a6ce-64524c2fe2f2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "841/841 [==============================] - 193s 224ms/step - loss: 0.4821 - accuracy: 0.7639 - val_loss: 0.4308 - val_accuracy: 0.7994\n",
            "Epoch 2/10\n",
            "841/841 [==============================] - 192s 229ms/step - loss: 0.4178 - accuracy: 0.8069 - val_loss: 0.4041 - val_accuracy: 0.8125\n",
            "Epoch 3/10\n",
            "841/841 [==============================] - 191s 227ms/step - loss: 0.3940 - accuracy: 0.8204 - val_loss: 0.3968 - val_accuracy: 0.8187\n",
            "Epoch 4/10\n",
            "841/841 [==============================] - 186s 222ms/step - loss: 0.3772 - accuracy: 0.8295 - val_loss: 0.3893 - val_accuracy: 0.8231\n",
            "Epoch 5/10\n",
            "841/841 [==============================] - 187s 223ms/step - loss: 0.3636 - accuracy: 0.8381 - val_loss: 0.3983 - val_accuracy: 0.8223\n",
            "Epoch 6/10\n",
            "841/841 [==============================] - 193s 229ms/step - loss: 0.3493 - accuracy: 0.8458 - val_loss: 0.3879 - val_accuracy: 0.8231\n",
            "Epoch 7/10\n",
            "841/841 [==============================] - 192s 229ms/step - loss: 0.3388 - accuracy: 0.8507 - val_loss: 0.4032 - val_accuracy: 0.8119\n",
            "Epoch 8/10\n",
            "841/841 [==============================] - 192s 229ms/step - loss: 0.3307 - accuracy: 0.8547 - val_loss: 0.3925 - val_accuracy: 0.8220\n",
            "Epoch 9/10\n",
            "841/841 [==============================] - 192s 228ms/step - loss: 0.3208 - accuracy: 0.8602 - val_loss: 0.3930 - val_accuracy: 0.8244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f071d7b8910>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = CNNLSTM.predict(combined_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "misclassified_samples = 0\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] != test_y[i]:\n",
        "        original_sentence = tokenizer.sequences_to_texts([combined_X_test[i]])[0]\n",
        "        actual_label = test_y[i]\n",
        "        predicted_label = y_pred[i][0]\n",
        "        print(\"Sentence: \", original_sentence)\n",
        "        print(\"Actual Label: \", actual_label)\n",
        "        print(\"Predicted Label: \", predicted_label)\n",
        "        print(\" \")\n",
        "        misclassified_samples += 1\n",
        "    if misclassified_samples >= 5:\n",
        "        break\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(test_y, y_pred))"
      ],
      "metadata": {
        "id": "-H79F5pYicoJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e2d2072c-b834-4822-d52b-466958323fce"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1121/1121 [==============================] - 24s 21ms/step\n",
            "Sentence:  thanks to covid the olympics are cancelled and these were the first olympics where men could compete as women because thank you covid\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  how do you make a plumber cry you kill his family\n",
            "Actual Label:  0\n",
            "Predicted Label:  1\n",
            " \n",
            "Sentence:  how to play these niggas and bitches that be snakes\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  and you are in what position to give out orders dictate and judge exactly none none whatsoever you are only making yourself look absolute pathetic by saying such nonsense and in regard to your reference of the source being totally a reliable and accurate source give me a break very professional of yourself fueled with anti welsh sentiments too i gather let me know when you come to seoul to visit your professional father your comments prove that the professional genes have not blessed yourself\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Sentence:  bolest reba recite\n",
            "Actual Label:  1\n",
            "Predicted Label:  0\n",
            " \n",
            "Accuracy: 0.825\n",
            "Precision: 0.791\n",
            "Recall: 0.820\n",
            "F1: 0.806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outside Testing**"
      ],
      "metadata": {
        "id": "gbWOr_ZqhH2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HSD Dataset"
      ],
      "metadata": {
        "id": "QS7mq50DVKZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "o-vrk7ML9sKo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outside_data = pd.read_csv('merged_hate.csv',engine='python')\n",
        "test_X = outside_data['contents'].values\n",
        "new_test_y = outside_data['label'].values"
      ],
      "metadata": {
        "id": "ZM5ouH8rVJtc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "3x7JPM4UZ6XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit vectorizer on testing data\n",
        "nb_new_test_X = vectorizer.transform(test_X)"
      ],
      "metadata": {
        "id": "y9ykaGVrVOlD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = naive.predict(nb_new_test_X)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S6UQ1im9VS-Z",
        "outputId": "3dbffcfd-ea1c-4f85-a670-a20f08c636e3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.763\n",
            "Precision: 0.752\n",
            "Recall: 0.783\n",
            "F1: 0.767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "oDsYs1FfaA2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_X_new_test = tokenizer.texts_to_sequences(test_X)\n",
        "cnn_X_new_test = pad_sequences(cnn_X_new_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "# make predictions on the test data\n",
        "y_pred = cnn.predict(cnn_X_new_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "# evaluate the model's performance\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ila-G6aktNwn",
        "outputId": "b9a4acdf-541f-41d9-df26-8966a78bcc9e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 1s 9ms/step\n",
            "Accuracy: 0.757\n",
            "Precision: 0.785\n",
            "Recall: 0.707\n",
            "F1: 0.744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN**"
      ],
      "metadata": {
        "id": "70-3XqEJt9Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_X_new_test = tokenizer.texts_to_sequences(test_X)\n",
        "rnn_X_new_test = pad_sequences(rnn_X_new_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "y_pred = rnn.predict(rnn_X_new_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FyQYf1bJuA5y",
        "outputId": "e2cf00a0-f6ef-4cb8-a162-cbe0920f7bd6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 2s 21ms/step\n",
            "Accuracy: 0.793\n",
            "Precision: 0.805\n",
            "Recall: 0.773\n",
            "F1: 0.788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined CNN-LSTM**"
      ],
      "metadata": {
        "id": "AnIaFypxu2r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_X_test = tokenizer.texts_to_sequences(test_X)\n",
        "combined_X_test = pad_sequences(combined_X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "y_pred = CNNLSTM.predict(combined_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZoayfYPtuzWR",
        "outputId": "06c4b921-bb27-4f1d-e25b-ca419fc763b8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 1s 18ms/step\n",
            "Accuracy: 0.787\n",
            "Precision: 0.791\n",
            "Recall: 0.780\n",
            "F1: 0.786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Davidson Hate Speech Dataset"
      ],
      "metadata": {
        "id": "5yga1ylizK3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "davidson_data = pd.read_csv('davidson_data.csv',engine='python')\n",
        "test_X = davidson_data['tweet'].values\n",
        "new_test_y = davidson_data['class'].values"
      ],
      "metadata": {
        "id": "HxmfVETRzPYv"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "0NkP7mYszaVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit vectorizer on testing data\n",
        "nb_new_test_X = vectorizer.transform(test_X)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = naive.predict(nb_new_test_X)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7scND61wzf9R",
        "outputId": "b41400fe-502e-4d29-b3b0-5b5711eb7908"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.801\n",
            "Precision: 0.753\n",
            "Recall: 0.897\n",
            "F1: 0.819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "lEi_BzB0zxGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_X_new_test = tokenizer.texts_to_sequences(test_X)\n",
        "cnn_X_new_test = pad_sequences(cnn_X_new_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "# make predictions on the test data\n",
        "y_pred = cnn.predict(cnn_X_new_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "# evaluate the model's performance\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uY9frV_MzwbQ",
        "outputId": "b61aefd4-aa4d-4fa3-a48e-b09c673eba12"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.760\n",
            "Precision: 0.757\n",
            "Recall: 0.766\n",
            "F1: 0.761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN**"
      ],
      "metadata": {
        "id": "Av-6V361z9WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_X_new_test = tokenizer.texts_to_sequences(test_X)\n",
        "rnn_X_new_test = pad_sequences(rnn_X_new_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "y_pred = rnn.predict(rnn_X_new_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iClIIJlsz_ic",
        "outputId": "9c206a34-9874-4908-f3c6-8912bee85d8b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 21ms/step\n",
            "Accuracy: 0.792\n",
            "Precision: 0.781\n",
            "Recall: 0.811\n",
            "F1: 0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined CNN-LSTM**"
      ],
      "metadata": {
        "id": "KD1RSiKl0GHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_X_test = tokenizer.texts_to_sequences(test_X)\n",
        "combined_X_test = pad_sequences(combined_X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "y_pred = CNNLSTM.predict(combined_X_test)\n",
        "y_pred = (y_pred > 0.5).astype('int32')\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print('Accuracy: %.3f' % accuracy_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Precision: %.3f' % precision_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('Recall: %.3f' % recall_score(new_test_y, y_pred))\n",
        "\t\n",
        "print('F1: %.3f' % f1_score(new_test_y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "38e_An1n0LYP",
        "outputId": "a4c1d7fe-ca6c-46f4-b4f4-bfae7ef8bbf8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 20ms/step\n",
            "Accuracy: 0.790\n",
            "Precision: 0.770\n",
            "Recall: 0.827\n",
            "F1: 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8_08VAlhRNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}