{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dc8d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f46eb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the csv \n",
    "data = pd.read_csv('hate_speech_data.csv')\n",
    "\n",
    "# making sure that the non-hate data and hate data both have 100,000 records \n",
    "label_data = data.loc[data['Label'] == '0']\n",
    "non_hate_data = label_data.sample(100000)\n",
    "hate_data = data.loc[data['Label'] == '1']\n",
    "\n",
    "# creating it into a new csv\n",
    "frames = [hate_data, non_hate_data]\n",
    "new_data = pd.concat(frames)\n",
    "new_data.to_csv(\"updated_hate_speech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58c113a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the new csv \n",
    "updated_hate_speech = pd.read_csv('updated_hate_speech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26b8b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# combine all the text files that contain the hate and non-hate speech into one csv \n",
    "# set the path of the folder containing the files\n",
    "folder_path = 'hate_speech_vicom/'\n",
    "\n",
    "# set the name of the new file to be created\n",
    "new_file_name = 'combined.csv'\n",
    "\n",
    "# get a list of all the files in the folder\n",
    "file_list = glob.glob(folder_path + '*.txt')\n",
    "\n",
    "# open the new file for writing\n",
    "with open(new_file_name, 'w', newline='') as outfile:\n",
    "    # create a CSV writer object\n",
    "    writer = csv.writer(outfile)\n",
    "    # write the header row with column names\n",
    "    writer.writerow(['file_id', 'contents'])\n",
    "    # loop through all the files in the folder\n",
    "    for filename in file_list:\n",
    "        # get the name of the file without the path and extension\n",
    "        file_title = os.path.splitext(os.path.basename(filename))[0]\n",
    "        # open each file for reading\n",
    "        with open(filename, 'r') as infile:\n",
    "            # read the contents of the file\n",
    "            contents = infile.read().strip()\n",
    "            # write the file title and contents to the new CSV file\n",
    "            writer.writerow([file_title, contents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64582447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file \n",
    "new = pd.read_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2f76841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv that contains whether something is considered hate or non hate \n",
    "label = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8df63547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two csvs on the file id\n",
    "merged_df = pd.merge(new, label, on='file_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3a638fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change noHate to 0 and  hate 1 to support the previous models\n",
    "merged_df.loc[merged_df[\"label\"] == \"noHate\", \"label\"] = 0\n",
    "merged_df.loc[merged_df[\"label\"] == \"hate\", \"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10d8bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows that have labels that aren't hate or non hate \n",
    "merged_df.drop(merged_df[merged_df['label'] == 'idk/skip'].index, inplace = True)\n",
    "merged_df.drop(merged_df[merged_df['label'] == 'relation'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9a9e4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change the type of the label to int\n",
    "merged_df['label'] = merged_df['label'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24c0b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure that the non-hate data and hate data both have 1196 records \n",
    "label_data = merged_df.loc[merged_df['label'] == 0]\n",
    "non_hate_data = label_data.sample(1196)\n",
    "hate_data = merged_df.loc[merged_df['label'] == 1]\n",
    "frames = [hate_data, non_hate_data]\n",
    "merged_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a8c3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe to a csv \n",
    "merged_df.to_csv('merged_hate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49bb890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>contents</th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33222250_1</td>\n",
       "      <td>I would not be surprised if this woman was spe...</td>\n",
       "      <td>572710</td>\n",
       "      <td>1346</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13481672_2</td>\n",
       "      <td>If they were jew pieces of garbage who the hel...</td>\n",
       "      <td>584956</td>\n",
       "      <td>1345</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13456820_1</td>\n",
       "      <td>Put that fat Black idiot to work and she would...</td>\n",
       "      <td>572059</td>\n",
       "      <td>1347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13456898_1</td>\n",
       "      <td>I know exactly what you 're saying , I just ha...</td>\n",
       "      <td>572496</td>\n",
       "      <td>1396</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14678603_1</td>\n",
       "      <td>I am White and I believe all White people know...</td>\n",
       "      <td>572073</td>\n",
       "      <td>1371</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>13494421_1</td>\n",
       "      <td>The reasons : Alcoholism takes around 150000 l...</td>\n",
       "      <td>584433</td>\n",
       "      <td>1395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>13457473_2</td>\n",
       "      <td>YouTube - BLACK WOMAN GOES BALLISTIC ON REPORT...</td>\n",
       "      <td>572158</td>\n",
       "      <td>1347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>31708555_1</td>\n",
       "      <td>oh definitely do push ups and sit ups for the ...</td>\n",
       "      <td>573774</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>14112998_3</td>\n",
       "      <td>Camie</td>\n",
       "      <td>572043</td>\n",
       "      <td>1381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>13472253_2</td>\n",
       "      <td>Most of my food is meat and produce .</td>\n",
       "      <td>572067</td>\n",
       "      <td>1346</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_id                                           contents  user_id  \\\n",
       "0     33222250_1  I would not be surprised if this woman was spe...   572710   \n",
       "1     13481672_2  If they were jew pieces of garbage who the hel...   584956   \n",
       "2     13456820_1  Put that fat Black idiot to work and she would...   572059   \n",
       "3     13456898_1  I know exactly what you 're saying , I just ha...   572496   \n",
       "4     14678603_1  I am White and I believe all White people know...   572073   \n",
       "...          ...                                                ...      ...   \n",
       "2387  13494421_1  The reasons : Alcoholism takes around 150000 l...   584433   \n",
       "2388  13457473_2  YouTube - BLACK WOMAN GOES BALLISTIC ON REPORT...   572158   \n",
       "2389  31708555_1  oh definitely do push ups and sit ups for the ...   573774   \n",
       "2390  14112998_3                                              Camie   572043   \n",
       "2391  13472253_2              Most of my food is meat and produce .   572067   \n",
       "\n",
       "      subforum_id  num_contexts  label  \n",
       "0            1346             2      1  \n",
       "1            1345             0      1  \n",
       "2            1347             0      1  \n",
       "3            1396             0      1  \n",
       "4            1371             0      1  \n",
       "...           ...           ...    ...  \n",
       "2387         1395             0      0  \n",
       "2388         1347             0      0  \n",
       "2389         1363             0      0  \n",
       "2390         1381             0      0  \n",
       "2391         1346             2      0  \n",
       "\n",
       "[2392 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv \n",
    "pd.read_csv('merged_hate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b6315a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the csv file from the Davidson Hate Speech data set \n",
    "davidson_data = pd.read_csv(\"labeled_data.csv\")\n",
    "\n",
    "# drop the unnecessary rows \n",
    "davidson_data.drop(davidson_data[davidson_data['class'] == 1].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "615effa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-number the columns so that it follows the same numbering as our original data set \n",
    "davidson_data.loc[davidson_data[\"class\"] == 0, \"class\"] = 1\n",
    "davidson_data.loc[davidson_data[\"class\"] == 2, \"class\"] = 0\n",
    "\n",
    "# making sure that the non-hate data and hate data both have 1430 records \n",
    "label_data = davidson_data.loc[davidson_data['class'] == 0]\n",
    "non_hate_data = label_data.sample(1430)\n",
    "hate_data = davidson_data.loc[davidson_data['class'] == 1]\n",
    "\n",
    "# merging them into a dataframe and then saving it as a csv \n",
    "frames = [hate_data, non_hate_data]\n",
    "new_data = pd.concat(frames)\n",
    "new_data.to_csv(\"davidson_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1568e2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24767</th>\n",
       "      <td>25280</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you know what they say, the early bird gets th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>25289</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you're all niggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24777</th>\n",
       "      <td>25290</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>you're such a retard i hope you get type 2 dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5593 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      0   \n",
       "40             40      3            0                   1        2      0   \n",
       "63             63      3            0                   0        3      0   \n",
       "66             66      3            0                   1        2      0   \n",
       "67             67      3            0                   1        2      0   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24767       25280      3            0                   1        2      0   \n",
       "24776       25289      3            3                   0        0      1   \n",
       "24777       25290      3            2                   1        0      1   \n",
       "24779       25292      3            0                   1        2      0   \n",
       "24782       25296      3            0                   0        3      0   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "40       \" momma said no pussy cats inside my doghouse \"  \n",
       "63     \"@Addicted2Guys: -SimplyAddictedToGuys http://...  \n",
       "66     \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...  \n",
       "67     \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...  \n",
       "...                                                  ...  \n",
       "24767  you know what they say, the early bird gets th...  \n",
       "24776                                 you're all niggers  \n",
       "24777  you're such a retard i hope you get type 2 dia...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[5593 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davidson_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8994766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the index \n",
    "davidson_data.to_csv('davidson_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8fe4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
